{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## **Translation**\n\n### **Sequence-to-Sequence Task**\n\n- Dịch máy là bài toán chuyển đổi từ chuỗi này sang chuỗi khác → **giống tóm tắt văn bản**.\n- Các bài toán tương tự khác:\n  - **Style transfer**: chuyển đổi phong cách viết.\n  - **Generative QA**: sinh câu trả lời từ ngữ cảnh.\n\n---\n\n### **Hai hướng tiếp cận chính**\n\n| Cách làm | Mô tả |\n|---------|-------|\n| **Huấn luyện từ đầu** | Nếu có **corpus lớn song ngữ**, bạn có thể huấn luyện một mô hình dịch mới hoàn toàn. |\n| **Fine-tune mô hình có sẵn** | Tiết kiệm thời gian, hiệu quả hơn. Có thể fine-tune: <br> - Mô hình đa ngôn ngữ như **mT5**, **mBART** <br> - Mô hình chuyên biệt cho cặp ngôn ngữ như **MarianMT** |\n\n---\n\n### **Thí nghiệm: Fine-tune MarianMT trên bộ dữ liệu KDE4**\n\n- **MarianMT**: Mô hình chuyên dịch, pretrained với dữ liệu từ bộ **Opus**.\n- **KDE4**: Bộ dữ liệu gồm các tập tin đã được dịch cho ứng dụng KDE (giàu nội dung kỹ thuật).\n- Dù MarianMT đã thấy dữ liệu này trong pretraining, **fine-tune vẫn giúp tăng hiệu năng** cho domain cụ thể.\n\n---\n\n### **Tại sao nên fine-tune?**\n\n- Mô hình gốc học tổng quát → chưa tối ưu cho ngữ cảnh hẹp (domain-specific).\n- Fine-tuning giúp mô hình **tập trung và chuẩn hóa hơn với cách dùng từ, ngữ pháp đặc trưng** trong lĩnh vực cụ thể (vd. giao diện phần mềm KDE).\n\n---","metadata":{}},{"cell_type":"markdown","source":"### **Preparing the Data**\nĐể fine-tune hoặc huấn luyện một mô hình dịch thuật từ đầu, ta cần một tập dữ liệu song ngữ — nghĩa là mỗi câu trong một ngôn ngữ phải đi kèm với bản dịch của nó trong ngôn ngữ kia. Dataset **KDE4** là một ví dụ điển hình, thường được dùng cho các cặp ngôn ngữ như tiếng Anh và tiếng Đức.","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\nraw_datasets = load_dataset(\"kde4\", lang1=\"en\", lang2=\"fr\")\n\nraw_datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T14:36:53.533147Z","iopub.execute_input":"2025-04-17T14:36:53.533466Z","iopub.status.idle":"2025-04-17T14:37:09.703832Z","shell.execute_reply.started":"2025-04-17T14:36:53.533441Z","shell.execute_reply":"2025-04-17T14:37:09.702820Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.10k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4769652cffea48c6b50dc7da47713afe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"kde4.py:   0%|          | 0.00/4.25k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58f337bf28d64ab79f86aa32a85402ef"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for kde4 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/kde4.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/7.05M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"507e90f88deb4c1b825d10d612d4f7b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/210173 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a775b463a064f6b83242a121d7a6c63"}},"metadata":{}},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'translation'],\n        num_rows: 210173\n    })\n})"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"split_datasets = raw_datasets[\"train\"].train_test_split(train_size=0.9, seed=20)\nsplit_datasets[\"validation\"] = split_datasets.pop(\"test\")\nsplit_datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T14:37:50.002925Z","iopub.execute_input":"2025-04-17T14:37:50.003313Z","iopub.status.idle":"2025-04-17T14:37:50.016934Z","shell.execute_reply.started":"2025-04-17T14:37:50.003286Z","shell.execute_reply":"2025-04-17T14:37:50.015938Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'translation'],\n        num_rows: 189155\n    })\n    validation: Dataset({\n        features: ['id', 'translation'],\n        num_rows: 21018\n    })\n})"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"split_datasets[\"train\"][1][\"translation\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T14:38:02.879963Z","iopub.execute_input":"2025-04-17T14:38:02.880323Z","iopub.status.idle":"2025-04-17T14:38:02.887083Z","shell.execute_reply.started":"2025-04-17T14:38:02.880292Z","shell.execute_reply":"2025-04-17T14:38:02.886314Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'en': 'Default to expanded threads',\n 'fr': 'Par défaut, développer les fils de discussion'}"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"Dataset này cung cấp các cặp câu song ngữ theo ngôn ngữ yêu cầu. Tuy nhiên, có một điểm đặc biệt: mặc dù đây là dữ liệu chuyên ngành kỹ thuật máy tính và được dịch sang tiếng Pháp đầy đủ, nhưng nhiều thuật ngữ kỹ thuật như “threads” thường được giữ nguyên tiếng Anh trong thực tế. Trong khi đó, dataset này lại dịch thành “fils de discussion”. Mô hình pretrained mà ta sử dụng — vốn đã học trên tập dữ liệu lớn chứa cả tiếng Pháp và tiếng Anh — thường chọn cách đơn giản hơn: giữ nguyên từ gốc tiếng Anh.","metadata":{}},{"cell_type":"markdown","source":"### **Processing the data**\n1. **Tạo tokenizer**  \n   Sử dụng `AutoTokenizer` từ Hugging Face để tải tokenizer tương ứng với mô hình pretrained dịch Anh → Pháp\n   \n   Nếu bạn dùng tokenizer đa ngôn ngữ (như mBART, M2M100), cần thiết lập `tokenizer.src_lang` và `tokenizer.tgt_lang`.","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nmodel_checkpoint = \"Helsinki-NLP/opus-mt-en-fr\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors=\"pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T14:43:36.537616Z","iopub.execute_input":"2025-04-17T14:43:36.538370Z","iopub.status.idle":"2025-04-17T14:43:48.256152Z","shell.execute_reply.started":"2025-04-17T14:43:36.538336Z","shell.execute_reply":"2025-04-17T14:43:48.255364Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92847fb0269442359b2cf1071ee3ad36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb863a16825a418e8906b73a8f995dda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"source.spm:   0%|          | 0.00/778k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8288154a83a94155a84908fe13b16e3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"target.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c99dc31c0a34848bfc06ef10a101513"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.34M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"242487fba5a046f394d28926bbf23a23"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"2. **Token hóa input và target**  \n   Phải **token hóa cả câu nguồn và câu đích**. Dữ liệu đầu vào (tiếng Anh) và đích (tiếng Pháp) được đưa qua `tokenizer` với `text_target` để xử lý đúng:\n   \n   ⚠️ Nếu bạn quên `text_target`, tokenizer sẽ xử lý target như câu tiếng Anh, gây ra lỗi tokenization do không nhận diện từ vựng tiếng Pháp.","metadata":{}},{"cell_type":"code","source":"en_sentence = split_datasets[\"train\"][1][\"translation\"][\"en\"]\nfr_sentence = split_datasets[\"train\"][1][\"translation\"][\"fr\"]\n\ninputs = tokenizer(en_sentence, text_target=fr_sentence)\ninputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T14:43:48.257295Z","iopub.execute_input":"2025-04-17T14:43:48.257836Z","iopub.status.idle":"2025-04-17T14:43:48.268240Z","shell.execute_reply.started":"2025-04-17T14:43:48.257807Z","shell.execute_reply":"2025-04-17T14:43:48.267398Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [47591, 12, 9842, 19634, 9, 0], 'attention_mask': [1, 1, 1, 1, 1, 1], 'labels': [577, 5891, 2, 3184, 16, 2542, 5, 1710, 0]}"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"wrong_targets = tokenizer(fr_sentence)\nprint(tokenizer.convert_ids_to_tokens(wrong_targets[\"input_ids\"]))\nprint(tokenizer.convert_ids_to_tokens(inputs[\"labels\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T14:43:48.269118Z","iopub.execute_input":"2025-04-17T14:43:48.269422Z","iopub.status.idle":"2025-04-17T14:43:48.288821Z","shell.execute_reply.started":"2025-04-17T14:43:48.269398Z","shell.execute_reply":"2025-04-17T14:43:48.287868Z"}},"outputs":[{"name":"stdout","text":"['▁Par', '▁dé', 'f', 'aut', ',', '▁dé', 've', 'lop', 'per', '▁les', '▁fil', 's', '▁de', '▁discussion', '</s>']\n['▁Par', '▁défaut', ',', '▁développer', '▁les', '▁fils', '▁de', '▁discussion', '</s>']\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"3. **Hàm tiền xử lý dữ liệu**  ","metadata":{}},{"cell_type":"code","source":"max_length = 128\n\n\ndef preprocess_function(examples):\n    inputs = [ex[\"en\"] for ex in examples[\"translation\"]]\n    targets = [ex[\"fr\"] for ex in examples[\"translation\"]]\n    model_inputs = tokenizer(\n        inputs, text_target=targets, max_length=max_length, truncation=True\n    )\n    return model_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T14:43:48.290553Z","iopub.execute_input":"2025-04-17T14:43:48.290857Z","iopub.status.idle":"2025-04-17T14:43:48.305000Z","shell.execute_reply.started":"2025-04-17T14:43:48.290836Z","shell.execute_reply":"2025-04-17T14:43:48.304088Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"4. **Áp dụng tiền xử lý lên dataset**  \n\n5. **Lưu ý thêm:**  \n   - Với mô hình **T5**, cần thêm prefix vào input: `\"translate English to French: <text>\"`\n   - Không cần attention mask cho target.\n   - Padding token trong labels phải chuyển thành `-100` để không ảnh hưởng khi tính loss (được xử lý tự động nếu bạn dùng data collator với dynamic padding).","metadata":{}},{"cell_type":"code","source":"tokenized_datasets = split_datasets.map(\n    preprocess_function,\n    batched=True,\n    remove_columns=split_datasets[\"train\"].column_names,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T14:43:48.305929Z","iopub.execute_input":"2025-04-17T14:43:48.306317Z","iopub.status.idle":"2025-04-17T14:44:38.068280Z","shell.execute_reply.started":"2025-04-17T14:43:48.306278Z","shell.execute_reply":"2025-04-17T14:44:38.067320Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/189155 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de71e9b61fac407b9ecf5285ecb8facb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/21018 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9453334c51a3457abfe397c5c8a4cd98"}},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"#### **Data collation**\n\nĐể huấn luyện mô hình dịch máy, ta cần xử lý padding một cách phù hợp cho cả **inputs** và **labels**. Đây là lý do ta sử dụng `DataCollatorForSeq2Seq` thay vì `DataCollatorWithPadding`.\n\n---\n\n1. Vì sao không dùng `DataCollatorWithPadding`?\n\n- `DataCollatorWithPadding` chỉ pad `input_ids`, `attention_mask` (và `token_type_ids` nếu có).\n- Với mô hình Seq2Seq, **labels cũng cần được padding**.\n- Giá trị padding của labels phải là `-100`, để tránh ảnh hưởng đến loss khi tính toán.\n\n---\n\n2. Sử dụng `DataCollatorForSeq2Seq`\n\n- `model` được truyền vào vì collator sẽ tạo `decoder_input_ids`, tức là phiên bản dịch được **shift** sang phải với một token đặc biệt ở đầu.\n- Cách shift khác nhau tuỳ kiến trúc mô hình nên cần truyền vào `model`.","metadata":{}},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\nfrom transformers import AutoModelForSeq2SeqLM\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n\nbatch = data_collator([tokenized_datasets[\"train\"][i] for i in range(1, 3)])\nbatch.keys()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T14:48:53.193468Z","iopub.execute_input":"2025-04-17T14:48:53.194210Z","iopub.status.idle":"2025-04-17T14:48:53.918935Z","shell.execute_reply.started":"2025-04-17T14:48:53.194182Z","shell.execute_reply":"2025-04-17T14:48:53.918196Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"dict_keys(['input_ids', 'attention_mask', 'labels', 'decoder_input_ids'])"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"### **Metrics**\n\n#### **Tại sao dùng `Seq2SeqTrainer`?**\n\nKhác với `Trainer` thông thường, `Seq2SeqTrainer` hỗ trợ:\n- Tự động gọi `generate()` khi đánh giá (`predict_with_generate=True`), giúp mô phỏng quá trình inference thực tế.\n- Tự xử lý các bước đặc biệt như `decoder_input_ids`, `attention mask`,…\n\n---\n\n#### **Dùng BLEU và SacreBLEU**\n\nBLEU là metric phổ biến cho bài toán dịch, nhưng có hạn chế vì cần **token hóa trước**.  \n→ Thay vào đó, ta dùng **SacreBLEU**, một phiên bản chuẩn hóa, dễ so sánh hơn.\n\n---","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install sacrebleu evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T14:49:32.236889Z","iopub.execute_input":"2025-04-17T14:49:32.237229Z","iopub.status.idle":"2025-04-17T14:49:37.096393Z","shell.execute_reply.started":"2025-04-17T14:49:32.237206Z","shell.execute_reply":"2025-04-17T14:49:37.094925Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"import evaluate\n\nmetric = evaluate.load(\"sacrebleu\")\n\npredictions = [\n    \"This plugin lets you translate web pages between several languages automatically.\"\n]\nreferences = [\n    [\n        \"This plugin allows you to automatically translate web pages between several languages.\"\n    ]\n]\nmetric.compute(predictions=predictions, references=references)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T14:49:38.623586Z","iopub.execute_input":"2025-04-17T14:49:38.623930Z","iopub.status.idle":"2025-04-17T14:49:39.653469Z","shell.execute_reply.started":"2025-04-17T14:49:38.623901Z","shell.execute_reply":"2025-04-17T14:49:39.652401Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0dde74fddf3743cea514a3e9522552e8"}},"metadata":{}},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"{'score': 46.750469682990165,\n 'counts': [11, 6, 4, 3],\n 'totals': [12, 11, 10, 9],\n 'precisions': [91.66666666666667,\n  54.54545454545455,\n  40.0,\n  33.333333333333336],\n 'bp': 0.9200444146293233,\n 'sys_len': 12,\n 'ref_len': 13}"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"import numpy as np\n\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    # In case the model returns more than the prediction logits\n    if isinstance(preds, tuple):\n        preds = preds[0]\n\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n\n    # Replace -100s in the labels as we can't decode them\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    # Some simple post-processing\n    decoded_preds = [pred.strip() for pred in decoded_preds]\n    decoded_labels = [[label.strip()] for label in decoded_labels]\n\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n    return {\"bleu\": result[\"score\"]}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T14:49:42.613561Z","iopub.execute_input":"2025-04-17T14:49:42.613895Z","iopub.status.idle":"2025-04-17T14:49:42.620444Z","shell.execute_reply.started":"2025-04-17T14:49:42.613869Z","shell.execute_reply":"2025-04-17T14:49:42.619431Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"### **Fine-tuning the model**","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments\n\nargs = Seq2SeqTrainingArguments(\n    f\"marian-finetuned-kde4-en-to-fr\",\n    eval_strategy=\"no\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=64,\n    weight_decay=0.01,\n    save_total_limit=3,\n    num_train_epochs=3,\n    predict_with_generate=True,\n    fp16=True,\n    push_to_hub=False, # change to True if you want push to hub\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T14:52:22.121928Z","iopub.execute_input":"2025-04-17T14:52:22.122282Z","iopub.status.idle":"2025-04-17T14:52:22.130919Z","shell.execute_reply.started":"2025-04-17T14:52:22.122256Z","shell.execute_reply":"2025-04-17T14:52:22.130007Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer\n\ntrainer = Seq2SeqTrainer(\n    model,\n    args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T14:52:24.711951Z","iopub.execute_input":"2025-04-17T14:52:24.712713Z","iopub.status.idle":"2025-04-17T14:52:24.729885Z","shell.execute_reply.started":"2025-04-17T14:52:24.712683Z","shell.execute_reply":"2025-04-17T14:52:24.728840Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/543751272.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"trainer.evaluate(max_length=max_length) # check score before train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T14:52:41.215559Z","iopub.execute_input":"2025-04-17T14:52:41.216599Z","execution_failed":"2025-04-17T14:56:09.488Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1' max='329' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  1/329 : < :]\n    </div>\n    "},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-17T14:56:09.488Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.evaluate(max_length=max_length)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.push_to_hub(tags=\"translation\", commit_message=\"Training complete\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}